{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from shapely.geometry import shape, mapping\n",
    "from GISio import shp2df, df2shp\n",
    "import shapefile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in a shapefile using `fiona`\n",
    "more info here: https://github.com/Toblerity/Fiona  \n",
    "`fiona` manual: http://toblerity.org/shapely/manual.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fiona.open('data/YaharaLakes.shp') as src:\n",
    "    meta = src.meta\n",
    "    records = []\n",
    "    for line in src:\n",
    "        props = line['properties']\n",
    "        props['geometry'] = line.get('geometry', None)\n",
    "        records.append(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each record is a dictionary similar to the GeoJSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a `DataFrame` of the records\n",
    "* information on the geometric features is stored in a `'geometry'` column but is still in GeoJSON-style format\n",
    "* convert geometries to `shapely` features so we can do stuff with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records)\n",
    "df['geometry'] = [shape(g) for g in df.geometry]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect an individual feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lake_mendota = df.geometry[3]\n",
    "lake_mendota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lake_mendota.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### since the geometries are `shapely` objects, there are many things we can do with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely.affinity import rotate\n",
    "rotate(lake_mendota, 60.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the same shapefile with a filter\n",
    "* this can speed up reading from large datasets (such as NHDPlus) if only a subset of the features are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fiona.open('data/YaharaLakes.shp') as src:\n",
    "    meta = src.meta\n",
    "    records = []\n",
    "    for line in src.filter(bbox=(-89.48, 43.1, -89.37, 43.15)):\n",
    "        props = line['properties']\n",
    "        props['geometry'] = line.get('geometry', None)\n",
    "        records.append(props)\n",
    "    df2 = pd.DataFrame(records)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `GIS_utils`\n",
    "* `shp2df` is a macro around `fiona` and `shapely` that also handles null geometries, dbf files, boolean values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = shp2df('data/YaharaLakes.shp')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a `DataFrame` to a shapefile\n",
    "\n",
    "#### make a schema\n",
    "* since what we are writing out has the same structure as what we read in, we can recycle the schema. Otherwise, we'd have to make one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src.meta['schema']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define the coordinate system (if you want a .prj file)\n",
    "* we can also recycle this\n",
    "* but this can also be easily made if the [**epsg code**](http://www.epsg.org/) is known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src.meta['crs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fiona.crs import from_epsg\n",
    "from_epsg(4269)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert the `DataFrame` back to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "props = df.drop('geometry', axis=1).astype(object).to_dict(orient='records')\n",
    "props[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `shapely.geometry.mapping` converts the `shapely` objects back to GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapped = [mapping(g) for g in df.geometry]\n",
    "mapped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fiona.collection('data/YaharaLakes2.shp', \"w\", driver=\"ESRI Shapefile\", \n",
    "                      crs=src.meta['crs'], schema=src.meta['schema']) as output:\n",
    "    for i in range(len(props)):\n",
    "        output.write({'properties': props[i],\n",
    "                      'geometry': mapped[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `GIS_utils`\n",
    "* the `df2shp` macro uses `fiona` to write a `DataFrame` to a shapefile, taking care of the schem, coordinate system, and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2shp(df, 'data/YaharaLakes2.shp', epsg=4269)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pyshp` is an alternative to `fiona` that is written in pure python (`fiona` uses the OGR library)\n",
    "* does not handle coordinate system defintions (no prj files)  \n",
    "* also does not read dbf files for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src = sf.Reader('data/YaharaLakes.shp')\n",
    "src.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geoms = [shape(s) for s in src.iterShapes()]\n",
    "records = [tuple(r) + (geoms[i],) for i, r in enumerate(src.iterRecords())]\n",
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = [f[0] for f in src.fields[1:]] + ['geometry'] # discard the DeletionFlag field (not in records)\n",
    "df = pd.DataFrame(records, columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing with `pyshp`\n",
    "\n",
    "#### specify the shape type\n",
    "see https://en.wikipedia.org/wiki/Shapefile (scroll down to Shape Types table)\n",
    "* get the shape type from a feature in the `geometry` column (we're assuming that they are all the same type, as required by the shapefile format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "types = {'Polygon': 5,\n",
    "         'LineString': 3,\n",
    "         'Point': 1}\n",
    "geomtype = types[df.geometry[0].type]\n",
    "geomtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instantiate the shapefile writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = sf.Writer(geomtype)\n",
    "w.autoBalance = 1 # prevents mismatch between number of features and records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the fields if necessary to enforce the 10-character limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def enforce_10ch_limit(names):\n",
    "    \"\"\"Enforce 10 character limit for fieldnames.\n",
    "    Add suffix for duplicate names starting at 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    names : list of strings\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    names : list of unique strings of len <= 10.\n",
    "    \"\"\"\n",
    "    names = [n[:9]+'1' if len(n) > 10 else n\n",
    "             for n in names]\n",
    "    dups = {x:names.count(x) for x in names}\n",
    "    suffix = {n: list(range(len(cnt))) for n, cnt in dups.items() if cnt > 1}\n",
    "    for i, n in enumerate(names):\n",
    "        if dups[n] > 1:\n",
    "            names[i] = n[:9] + str(suffix[n].pop(0))\n",
    "    return names\n",
    "\n",
    "# version of the dataframe without the geometry column\n",
    "dfr = df.drop('geometry', axis=1)\n",
    "\n",
    "names = enforce_10ch_limit(dfr.columns)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify dtypes and write the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pyshp_field_info(dtypename):\n",
    "    \"\"\"Get pyshp dtype information for a given numpy dtype.\"\"\"\n",
    "    fields = {'int': ('N', 20, 0),\n",
    "              '<i': ('N', 20, 0),\n",
    "              'float': ('F', 20, 12),\n",
    "              '<f': ('F', 20, 0),\n",
    "              'bool': ('L', 1),\n",
    "              'b1': ('L', 1),\n",
    "              'str': ('C', 50),\n",
    "              'object': ('C', 50)}\n",
    "    k = [k for k in fields.keys() if k in dtypename.lower()]\n",
    "    if len(k) == 1:\n",
    "        return fields[k[0]]\n",
    "    else:\n",
    "        return fields['str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, npdtype in enumerate(dfr.dtypes):\n",
    "    w.field(names[i], *get_pyshp_field_info(npdtype.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write out the features and records, handling the different shapetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = df.geometry[0]\n",
    "mapping(g)['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geoms = df.geometry.tolist()\n",
    "props = dfr.astype(object).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the geometry and attributes for each record\n",
    "if geomtype == 5:\n",
    "    for i, r in enumerate(props):\n",
    "        w.poly(mapping(geoms[i])['coordinates'])\n",
    "        w.record(*r)\n",
    "elif geomtype == 3:\n",
    "    for i, r in enumerate(props):\n",
    "        w.line(mapping(geoms[i])['coordinates'])\n",
    "        w.record(*r)\n",
    "elif geomtype == 1:\n",
    "    for i, r in enumerate(props):\n",
    "        w.point((mapping(geoms[i])['coordinates']))\n",
    "        w.record(*r)\n",
    "w.save('data/YaharaLakes2.shp')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
